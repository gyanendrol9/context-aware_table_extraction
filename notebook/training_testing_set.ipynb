{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f12fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d9bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(image):\n",
    "    return cv.threshold(image, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)[1]\n",
    "\n",
    "def image_preprocessing(img_path):\n",
    "    img = cv.imread(img_path)\n",
    "#     img = cv.resize(img, (1200,800), interpolation = cv.INTER_AREA)\n",
    "    \n",
    "    #Binarization\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Do dilation and erosion to eliminate unwanted noises\n",
    "    kernel = np.ones((1,1), np.uint8)\n",
    "    img = cv.dilate(img, kernel, iterations=30)\n",
    "    img = cv.erode(img, kernel, iterations=30)\n",
    "\n",
    "    #thresholding\n",
    "    img = thresholding(img)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    h,w,c = img.shape\n",
    "    \n",
    "    return img,h,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f39bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(pil_img, prob, boxes):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    n_img = 0\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), COLORS * 100):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        cl = p.argmax()\n",
    "        text = f'{CLASSES[cl]}: {p[cl]:0.2f} {n_img}'\n",
    "        n_img+=1\n",
    "        ax.text(xmin, ymin, text, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Normalized the bounding box img_w, img_h = im_pil.size\n",
    "def get_normalized_bbox(b, size):\n",
    "    img_w, img_h = size\n",
    "    x0,y0,x1,y1 = b[0:4]\n",
    "    w = (x1-x0)/img_w\n",
    "    h = (y1-y0)/img_h\n",
    "    x_c =  (x0/img_w)+0.5*w\n",
    "    y_c =  (y0/img_h)+0.5*h\n",
    "    return [x_c,y_c,w,h]\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def detect(im, model, transform):\n",
    "    # mean-std normalize the input image (batch-size: 1)\n",
    "#     img = transform(im).unsqueeze(0)\n",
    "\n",
    "#     # demo model only support by default images with aspect ratio between 0.5 and 2\n",
    "#     # if you want to use images with an aspect ratio outside this range\n",
    "#     # rescale your image so that the maximum size is at most 1333 for best results\n",
    "#     assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'\n",
    "    \n",
    "    inputs = feature_extractor(images=im, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # propagate through the model\n",
    "#     outputs = model(img)\n",
    "\n",
    "    # keep only predictions with 0.7+ confidence\n",
    "    probas = outputs['logits'].softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > 0.4\n",
    "\n",
    "    # convert boxes from [0; 1] to image scales\n",
    "    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
    "    return probas[keep], bboxes_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dd70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/data/glosat/Code-Git/docExtractor-master/demo/output_files'\n",
    "img_directory = '/data/glosat/Code-Git/docformer/dataset/Finetuning/test/images'\n",
    "out_directory='/data/glosat/glosat_table_dataset/datasets/Test/table_bbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa605a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {img_directory}/*.jpg > filename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6af6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('filename.txt','r')\n",
    "files = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7653b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_bboxes = {}\n",
    "f_error = open('test_bbox_error.txt','w')\n",
    "for file in files:\n",
    "    file =  file.strip().split('/')\n",
    "    \n",
    "    file = file[-1].split('.')\n",
    "    \n",
    "    filename = file[0]+'_cell_bounding_box_v2.pkl'\n",
    "    try:\n",
    "        f = open(f'{directory}/{filename}','rb')\n",
    "        bb_box = pickle.load(f)\n",
    "        f.close()\n",
    "        correct_cells = bb_box[0]\n",
    "        blank_cells = bb_box[1]\n",
    "        exclude_cells = bb_box[2]\n",
    "        tables = bb_box[3]\n",
    "\n",
    "        bb_bboxes[file[0]] = bb_box\n",
    "    except:\n",
    "        f_error.write(filename+'\\n')\n",
    "        \n",
    "f_error.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f5ded63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = {}\n",
    "\n",
    "for file in bb_bboxes:\n",
    "    cell_coords = []\n",
    "    table_coords = []\n",
    "    img_path = f'{img_directory}/{file}.jpg'\n",
    "    img,h,w = image_preprocessing(img_path)\n",
    "    im_pil = Image.fromarray(img)\n",
    "    bb_box = bb_bboxes[file]\n",
    "    \n",
    "    correct_cells = bb_box[0]\n",
    "    blank_cells = bb_box[1]\n",
    "    exclude_cells = bb_box[2]\n",
    "    tables = bb_box[3]\n",
    "\n",
    "    for cell in correct_cells:\n",
    "        cell = get_normalized_bbox(cell,im_pil.size)\n",
    "        cell_coords.append([cell, (1,0,0,0) ]) #cell, correct/blank/error/padding\n",
    "\n",
    "    for cell in blank_cells:\n",
    "        cell = get_normalized_bbox(cell,im_pil.size)\n",
    "        cell_coords.append([cell, (0,1,0,0)])\n",
    "\n",
    "    for cell in exclude_cells:\n",
    "        cell = get_normalized_bbox(cell,im_pil.size)\n",
    "        cell_coords.append([cell, (0,0,1,0)])\n",
    "\n",
    "    for cell in tables:\n",
    "        cell = get_normalized_bbox(cell,im_pil.size) #cell, table/no-table  [can add bordered/borderless]\n",
    "        table_coords.append([cell, (1,0)])\n",
    "    \n",
    "    training_set[file] = (cell_coords,table_coords) #cells,tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7470bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set['412'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c1f000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/glosat/glosat_table_dataset/datasets/Test/table_bbox'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e6d9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'{out_directory}/table_cell_bbox.pkl', 'wb')\n",
    "pickle.dump(training_set,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44563ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##upto here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f4dacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_directory = '/data/glosat/Code-Git/docformer/dataset/Finetuning/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93836678",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fp = out_directory+'/table_bbox'\n",
    "files = os.listdir(label_fp)\n",
    "\n",
    "f = open(out_directory+'/table_bbox.pkl','rb')\n",
    "label = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "498acb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n",
      "100 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_189600/2175170980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0misExist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misExist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mim_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mim_pil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_189600/3307254650.py\u001b[0m in \u001b[0;36mimage_preprocessing\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#     img = cv.resize(img, (1200,800), interpolation = cv.INTER_AREA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for img in files:\n",
    "    if '.pkl' not in img:\n",
    "        img_file, ext = img.split('.')\n",
    "        filename, count = img_file.split('_')\n",
    "        img_path = os.path.join(out_directory,'images',filename+'.'+ext)\n",
    "        isExist = os.path.exists(out_directory)\n",
    "        if isExist:                \n",
    "            image, img_h, img_w = image_preprocessing(img_path)\n",
    "            im_pil = Image.fromarray(image)\n",
    "            im_pil = im_pil.resize((800,1200), Image.ANTIALIAS)\n",
    "\n",
    "            input_l = {}\n",
    "            bbox = label[int(filename)][0] +[[0,0,0,0]]*(100-len(label[int(filename)][0]))\n",
    "\n",
    "            labell = [label[int(filename)][1]]*len(label[int(filename)][0])+[[0,0,0]]*(100-len(label[int(filename)][0]))\n",
    "            \n",
    "            print(len(bbox),len(labell))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b733a4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.46674727932285365,\n",
       "  0.33026934587430523,\n",
       "  0.8875453446191052,\n",
       "  0.34074390765284307],\n",
       " [0.46674727932285365,\n",
       "  0.725096194955109,\n",
       "  0.8742442563482467,\n",
       "  0.3215049166310389],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f61b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
